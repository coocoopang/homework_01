#include "face_matcher.h"
#include <algorithm>
#include <cmath>
#include <iomanip>

FaceMatcher::FaceMatcher() 
    : videoSource(""), isVideoFile(false), cascadeLoaded(false),
      matchThreshold(0.7), detectorType("SIFT"), matcherType("BF"),
      minMatchCount(10), maxDistanceRatio(0.75) {
    
    // OpenCVì˜ ì‚¬ì „ í›ˆë ¨ëœ ì–¼êµ´ ê²€ì¶œê¸° ë¡œë“œ
    std::vector<std::string> cascadePaths = {
        "/usr/share/opencv4/haarcascades/haarcascade_frontalface_alt.xml",
        "/usr/local/share/opencv4/haarcascades/haarcascade_frontalface_alt.xml",
        "/usr/share/opencv4/haarcascades/haarcascade_frontalface_default.xml",
        "/usr/local/share/opencv4/haarcascades/haarcascade_frontalface_default.xml",
        "./haarcascades/haarcascade_frontalface_alt.xml",
        "./haarcascades/haarcascade_frontalface_default.xml",
        "haarcascade_frontalface_alt.xml",
        "haarcascade_frontalface_default.xml"
    };
    
    for (const auto& path : cascadePaths) {
        if (faceClassifier.load(path)) {
            cascadeLoaded = true;
            std::cout << "âœ… ì–¼êµ´ ê²€ì¶œê¸° ë¡œë“œ ì„±ê³µ: " << path << std::endl;
            break;
        }
    }
    
    if (!cascadeLoaded) {
        std::cerr << "âŒ ì–¼êµ´ ê²€ì¶œê¸° ë¡œë“œ ì‹¤íŒ¨! Haar cascade íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." << std::endl;
        std::cerr << "ğŸ“ í•´ê²°ë°©ë²•: Haar cascade íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  Project4 í´ë”ì— ë³µì‚¬í•˜ì„¸ìš”." << std::endl;
        std::cerr << "   wget https://raw.githubusercontent.com/opencv/opencv/4.x/data/haarcascades/haarcascade_frontalface_default.xml" << std::endl;
    }
    
    // ê¸°ë³¸ íŠ¹ì§•ì  ê²€ì¶œê¸°ì™€ ë§¤ì²˜ ìƒì„±
    detector = FeatureMatchingUtils::createFeatureDetector(detectorType);
    matcher = FeatureMatchingUtils::createDescriptorMatcher(matcherType, detectorType);
    
    std::cout << "ğŸ”§ íŠ¹ì§•ì  ê¸°ë°˜ ì–¼êµ´ ë§¤ì¹­ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!" << std::endl;
    std::cout << "   - íŠ¹ì§•ì  ê²€ì¶œê¸°: " << detectorType << std::endl;
    std::cout << "   - ë§¤ì²˜: " << matcherType << std::endl;
    std::cout << "   - ìµœì†Œ ë§¤ì¹­ ê°œìˆ˜: " << minMatchCount << std::endl;
}

FaceMatcher::~FaceMatcher() {
    if (videoCapture.isOpened()) {
        videoCapture.release();
    }
}

bool FaceMatcher::loadReferenceFace(const std::string& imagePath) {
    referenceFaceImage = cv::imread(imagePath, cv::IMREAD_COLOR);
    if (referenceFaceImage.empty()) {
        std::cerr << "âŒ ê¸°ì¤€ ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: " << imagePath << std::endl;
        return false;
    }
    
    // ì–¼êµ´ ê²€ì¶œ
    std::vector<cv::Rect> faces = detectFaces(referenceFaceImage);
    if (faces.empty()) {
        std::cerr << "âŒ ê¸°ì¤€ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!" << std::endl;
        return false;
    }
    
    // ê°€ì¥ í° ì–¼êµ´ì„ ê¸°ì¤€ìœ¼ë¡œ ì„ íƒ
    cv::Rect largestFace = *std::max_element(faces.begin(), faces.end(), 
        [](const cv::Rect& a, const cv::Rect& b) {
            return a.area() < b.area();
        });
    
    // ì–¼êµ´ ì˜ì—­ í™•ì¥ ë° ì¶”ì¶œ
    cv::Rect expandedFace = FeatureMatchingUtils::expandFaceRect(largestFace, referenceFaceImage.size());
    cv::Mat faceROI = referenceFaceImage(expandedFace).clone();
    
    // ì „ì²˜ë¦¬
    faceROI = preprocessFace(faceROI);
    
    // ê¸°ì¤€ ì–¼êµ´ì—ì„œ íŠ¹ì§•ì  ì¶”ì¶œ
    extractFeatures(faceROI, referenceKeypoints, referenceDescriptors);
    
    if (referenceKeypoints.empty()) {
        std::cerr << "âŒ ê¸°ì¤€ ì–¼êµ´ì—ì„œ íŠ¹ì§•ì ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!" << std::endl;
        return false;
    }
    
    double featureDensity = FeatureMatchingUtils::calculateFeatureDensity(referenceKeypoints, faceROI.size());
    
    std::cout << "âœ… ê¸°ì¤€ ì–¼êµ´ íŠ¹ì§•ì  ì¶”ì¶œ ì™„ë£Œ!" << std::endl;
    std::cout << "   - ì´ë¯¸ì§€ í¬ê¸°: " << faceROI.size() << std::endl;
    std::cout << "   - íŠ¹ì§•ì  ê°œìˆ˜: " << referenceKeypoints.size() << std::endl;
    std::cout << "   - íŠ¹ì§•ì  ë°€ë„: " << std::fixed << std::setprecision(4) << featureDensity << " points/pixelÂ²" << std::endl;
    
    return true;
}

bool FaceMatcher::startWebcam(int deviceId) {
    videoCapture.open(deviceId);
    if (!videoCapture.isOpened()) {
        std::cerr << "âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤! (Device ID: " << deviceId << ")" << std::endl;
        return false;
    }
    
    // ì›¹ìº  ì„¤ì •
    videoCapture.set(cv::CAP_PROP_FRAME_WIDTH, 640);
    videoCapture.set(cv::CAP_PROP_FRAME_HEIGHT, 480);
    videoCapture.set(cv::CAP_PROP_FPS, 30);
    
    videoSource = "webcam";
    isVideoFile = false;
    
    std::cout << "âœ… ì›¹ìº  ì‹œì‘ ì™„ë£Œ!" << std::endl;
    return true;
}

bool FaceMatcher::loadVideoFile(const std::string& videoPath) {
    videoCapture.open(videoPath);
    if (!videoCapture.isOpened()) {
        std::cerr << "âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: " << videoPath << std::endl;
        return false;
    }
    
    videoSource = videoPath;
    isVideoFile = true;
    
    // ë¹„ë””ì˜¤ ì •ë³´ ì¶œë ¥
    int totalFrames = static_cast<int>(videoCapture.get(cv::CAP_PROP_FRAME_COUNT));
    double fps = videoCapture.get(cv::CAP_PROP_FPS);
    int width = static_cast<int>(videoCapture.get(cv::CAP_PROP_FRAME_WIDTH));
    int height = static_cast<int>(videoCapture.get(cv::CAP_PROP_FRAME_HEIGHT));
    
    std::cout << "âœ… ë¹„ë””ì˜¤ íŒŒì¼ ë¡œë“œ ì™„ë£Œ!" << std::endl;
    std::cout << "ğŸ“ íŒŒì¼: " << videoPath << std::endl;
    std::cout << "ğŸ“Š ì •ë³´: " << width << "x" << height << ", " << fps << " FPS, " << totalFrames << " í”„ë ˆì„" << std::endl;
    
    return true;
}

void FaceMatcher::runFaceMatching() {
    if (!videoCapture.isOpened()) {
        std::cerr << "âŒ ë¹„ë””ì˜¤ ì†ŒìŠ¤ê°€ ì—´ë ¤ìˆì§€ ì•ŠìŠµë‹ˆë‹¤!" << std::endl;
        return;
    }
    
    if (referenceKeypoints.empty() || referenceDescriptors.empty()) {
        std::cerr << "âŒ ê¸°ì¤€ ì–¼êµ´ íŠ¹ì§•ì ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!" << std::endl;
        return;
    }
    
    std::string sourceType = isVideoFile ? "ë¹„ë””ì˜¤ íŒŒì¼" : "ì›¹ìº ";
    std::cout << "ğŸ¥ " << sourceType << " íŠ¹ì§•ì  ë§¤ì¹­ ì‹œì‘!" << std::endl;
    if (isVideoFile) {
        std::cout << "ğŸ“ íŒŒì¼: " << videoSource << std::endl;
    }
    
    std::cout << "ğŸ“‹ ì¡°ì‘ë²•:" << std::endl;
    std::cout << "   - ESC ë˜ëŠ” 'q': ì¢…ë£Œ" << std::endl;
    std::cout << "   - SPACE: ì¼ì‹œì •ì§€/ì¬ìƒ (ë¹„ë””ì˜¤ íŒŒì¼)" << std::endl;
    std::cout << "   - 't': ë§¤ì¹­ ì„ê³„ê°’ ì¡°ì •" << std::endl;
    std::cout << "   - 's': ìŠ¤í¬ë¦°ìƒ· ì €ì¥" << std::endl;
    std::cout << "   - 'd': íŠ¹ì§•ì  ê²€ì¶œê¸° ë³€ê²½ (SIFT â†” ORB)" << std::endl;
    std::cout << std::endl;
    
    cv::Mat frame;
    int frameCount = 0;
    int totalFrames = isVideoFile ? static_cast<int>(videoCapture.get(cv::CAP_PROP_FRAME_COUNT)) : 0;
    bool paused = false;
    
    while (true) {
        if (!paused || !isVideoFile) {
            videoCapture >> frame;
            if (frame.empty()) {
                if (isVideoFile) {
                    std::cout << "ğŸ“¹ ë¹„ë””ì˜¤ ì¬ìƒ ì™„ë£Œ!" << std::endl;
                }
                break;
            }
            frameCount++;
        }
        
        // ì–¼êµ´ ê²€ì¶œ
        std::vector<cv::Rect> faces = detectFaces(frame);
        
        // ê° ê²€ì¶œëœ ì–¼êµ´ì— ëŒ€í•´ íŠ¹ì§•ì  ë§¤ì¹­ ìˆ˜í–‰
        for (const auto& faceRect : faces) {
            // ì–¼êµ´ ì˜ì—­ í™•ì¥ ë° ì¶”ì¶œ
            cv::Rect expandedFace = FeatureMatchingUtils::expandFaceRect(faceRect, frame.size());
            cv::Mat detectedFace = frame(expandedFace);
            
            // íŠ¹ì§•ì  ê¸°ë°˜ ì–¼êµ´ ë§¤ì¹­
            double matchScore = matchFaceByFeatures(detectedFace);
            bool isMatch = matchScore >= matchThreshold;
            
            // ê²°ê³¼ í‘œì‹œ
            int matchCount = static_cast<int>(matchScore * 100); // ì„ì‹œë¡œ ë°±ë¶„ìœ¨ì„ ë§¤ì¹­ ê°œìˆ˜ë¡œ ì‚¬ìš©
            drawMatchResult(frame, expandedFace, matchScore, isMatch, matchCount);
        }
        
        // ì •ë³´ í‘œì‹œ
        std::string title = isVideoFile ? "Feature Matching - Video" : "Feature Matching - Webcam";
        cv::putText(frame, title, cv::Point(10, 30), 
                   cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 255, 0), 2);
        
        cv::putText(frame, "Threshold: " + std::to_string(int(matchThreshold * 100)) + "%", 
                   cv::Point(10, 60), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 255, 255), 1);
        cv::putText(frame, "Faces: " + std::to_string(faces.size()), 
                   cv::Point(10, 80), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 255, 255), 1);
        cv::putText(frame, "Detector: " + detectorType, 
                   cv::Point(10, 100), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 255, 255), 1);
        cv::putText(frame, "Ref Features: " + std::to_string(referenceKeypoints.size()), 
                   cv::Point(10, 120), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 255, 255), 1);
        
        // ë¹„ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš° í”„ë ˆì„ ì •ë³´ í‘œì‹œ
        if (isVideoFile) {
            std::string frameInfo = "Frame: " + std::to_string(frameCount) + "/" + std::to_string(totalFrames);
            cv::putText(frame, frameInfo, cv::Point(10, 140), 
                       cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 255, 255), 1);
            
            if (paused) {
                cv::putText(frame, "PAUSED", cv::Point(frame.cols/2 - 50, 50), 
                           cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(0, 255, 255), 3);
            }
        }
        
        // í™”ë©´ ì¶œë ¥
        cv::imshow(title, frame);
        
        // í‚¤ ì…ë ¥ ì²˜ë¦¬
        int waitTime = isVideoFile ? 30 : 1;
        int key = cv::waitKey(waitTime) & 0xFF;
        
        if (key == 27 || key == 'q') { // ESC ë˜ëŠ” 'q'
            break;
        } else if (key == ' ' && isVideoFile) { // SPACE - ì¼ì‹œì •ì§€/ì¬ìƒ
            paused = !paused;
            std::cout << (paused ? "â¸ï¸ ì¼ì‹œì •ì§€" : "â–¶ï¸ ì¬ìƒ") << std::endl;
        } else if (key == 't') { // ì„ê³„ê°’ ì¡°ì •
            std::cout << "í˜„ì¬ ì„ê³„ê°’: " << int(matchThreshold * 100) << "%" << std::endl;
            std::cout << "ìƒˆë¡œìš´ ì„ê³„ê°’ ì…ë ¥ (0-100): ";
            int newThreshold;
            std::cin >> newThreshold;
            matchThreshold = std::max(0, std::min(100, newThreshold)) / 100.0;
            std::cout << "ì„ê³„ê°’ ë³€ê²½: " << int(matchThreshold * 100) << "%" << std::endl;
        } else if (key == 's') { // ìŠ¤í¬ë¦°ìƒ·
            std::string filename = "screenshot_" + std::to_string(frameCount) + ".jpg";
            cv::imwrite(filename, frame);
            std::cout << "ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: " << filename << std::endl;
        } else if (key == 'd') { // íŠ¹ì§•ì  ê²€ì¶œê¸° ë³€ê²½
            detectorType = (detectorType == "SIFT") ? "ORB" : "SIFT";
            detector = FeatureMatchingUtils::createFeatureDetector(detectorType);
            matcher = FeatureMatchingUtils::createDescriptorMatcher(matcherType, detectorType);
            
            // ê¸°ì¤€ ì–¼êµ´ íŠ¹ì§•ì  ì¬ì¶”ì¶œ
            if (!referenceFaceImage.empty()) {
                std::vector<cv::Rect> faces = detectFaces(referenceFaceImage);
                if (!faces.empty()) {
                    cv::Rect largestFace = *std::max_element(faces.begin(), faces.end(), 
                        [](const cv::Rect& a, const cv::Rect& b) { return a.area() < b.area(); });
                    cv::Rect expandedFace = FeatureMatchingUtils::expandFaceRect(largestFace, referenceFaceImage.size());
                    cv::Mat faceROI = preprocessFace(referenceFaceImage(expandedFace));
                    extractFeatures(faceROI, referenceKeypoints, referenceDescriptors);
                }
            }
            
            std::cout << "ğŸ”„ íŠ¹ì§•ì  ê²€ì¶œê¸° ë³€ê²½: " << detectorType << " (ê¸°ì¤€ íŠ¹ì§•ì : " << referenceKeypoints.size() << "ê°œ)" << std::endl;
        }
    }
    
    cv::destroyAllWindows();
    std::cout << "ğŸ‘‹ íŠ¹ì§•ì  ë§¤ì¹­ ì¢…ë£Œ!" << std::endl;
}

void FaceMatcher::runVideoFaceMatching() {
    runFaceMatching();
}

std::vector<cv::Rect> FaceMatcher::detectFaces(const cv::Mat& frame) {
    std::vector<cv::Rect> faces;
    
    if (!cascadeLoaded || faceClassifier.empty()) {
        static bool errorShown = false;
        if (!errorShown) {
            std::cerr << "âš ï¸ ì–¼êµ´ ê²€ì¶œê¸°ê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ì–¼êµ´ ê²€ì¶œì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤." << std::endl;
            errorShown = true;
        }
        return faces;
    }
    
    if (frame.empty()) {
        std::cerr << "âš ï¸ ë¹ˆ í”„ë ˆì„ì´ ì…ë ¥ë˜ì—ˆìŠµë‹ˆë‹¤." << std::endl;
        return faces;
    }
    
    cv::Mat grayFrame;
    try {
        if (frame.channels() == 3) {
            cv::cvtColor(frame, grayFrame, cv::COLOR_BGR2GRAY);
        } else {
            grayFrame = frame.clone();
        }
        
        cv::equalizeHist(grayFrame, grayFrame);
        
        faceClassifier.detectMultiScale(
            grayFrame,
            faces,
            1.1,
            3,
            0 | cv::CASCADE_SCALE_IMAGE,
            cv::Size(30, 30),
            cv::Size()
        );
        
    } catch (const cv::Exception& e) {
        std::cerr << "âŒ detectMultiScale ì—ëŸ¬: " << e.what() << std::endl;
    }
    
    return faces;
}

double FaceMatcher::matchFaceByFeatures(const cv::Mat& detectedFace) {
    if (detectedFace.empty() || referenceDescriptors.empty()) {
        return 0.0;
    }
    
    // ì „ì²˜ë¦¬
    cv::Mat processedFace = preprocessFace(detectedFace);
    
    // íŠ¹ì§•ì  ì¶”ì¶œ
    std::vector<cv::KeyPoint> detectedKeypoints;
    cv::Mat detectedDescriptors;
    extractFeatures(processedFace, detectedKeypoints, detectedDescriptors);
    
    if (detectedKeypoints.empty() || detectedDescriptors.empty()) {
        return 0.0;
    }
    
    // ìµœê·¼ì ‘ ë§¤ì¹­
    std::vector<cv::DMatch> matches = findNearestMatches(referenceDescriptors, detectedDescriptors);
    
    if (matches.empty()) {
        return 0.0;
    }
    
    // ê¸°í•˜í•™ì  ê²€ì¦
    int verifiedMatches = verifyGeometry(referenceKeypoints, detectedKeypoints, matches);
    
    // ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
    double score = calculateMatchScore(verifiedMatches, referenceKeypoints.size());
    
    // ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥ (ê°œë°œ ì‹œì—ë§Œ)
    static int debugCount = 0;
    if (debugCount++ % 30 == 0) { // 30í”„ë ˆì„ë§ˆë‹¤ í•œ ë²ˆì”©
        printMatchingInfo(matches.size(), verifiedMatches, score);
    }
    
    return score;
}

void FaceMatcher::extractFeatures(const cv::Mat& image, std::vector<cv::KeyPoint>& keypoints, cv::Mat& descriptors) {
    if (!detector) {
        std::cerr << "âŒ íŠ¹ì§•ì  ê²€ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!" << std::endl;
        return;
    }
    
    try {
        detector->detectAndCompute(image, cv::noArray(), keypoints, descriptors);
    } catch (const cv::Exception& e) {
        std::cerr << "âŒ íŠ¹ì§•ì  ì¶”ì¶œ ì—ëŸ¬: " << e.what() << std::endl;
        keypoints.clear();
        descriptors = cv::Mat();
    }
}

std::vector<cv::DMatch> FaceMatcher::findNearestMatches(const cv::Mat& descriptors1, const cv::Mat& descriptors2) {
    std::vector<cv::DMatch> goodMatches;
    
    if (!matcher || descriptors1.empty() || descriptors2.empty()) {
        return goodMatches;
    }
    
    try {
        if (detectorType == "SIFT") {
            // SIFTì˜ ê²½ìš° k-NN ë§¤ì¹­ ì‚¬ìš© (Lowe's ratio test)
            std::vector<std::vector<cv::DMatch>> knnMatches;
            matcher->knnMatch(descriptors1, descriptors2, knnMatches, 2);
            goodMatches = filterGoodMatches(knnMatches);
        } else {
            // ORBì˜ ê²½ìš° ë‹¨ìˆœ ë§¤ì¹­ í›„ ê±°ë¦¬ ê¸°ë°˜ í•„í„°ë§
            std::vector<cv::DMatch> matches;
            matcher->match(descriptors1, descriptors2, matches);
            
            // ê±°ë¦¬ ê¸°ë°˜ í•„í„°ë§
            double maxDist = 0; double minDist = 100;
            for (const auto& match : matches) {
                double dist = match.distance;
                if (dist < minDist) minDist = dist;
                if (dist > maxDist) maxDist = dist;
            }
            
            double threshold = std::max(2 * minDist, 30.0);
            for (const auto& match : matches) {
                if (match.distance <= threshold) {
                    goodMatches.push_back(match);
                }
            }
        }
    } catch (const cv::Exception& e) {
        std::cerr << "âŒ íŠ¹ì§•ì  ë§¤ì¹­ ì—ëŸ¬: " << e.what() << std::endl;
    }
    
    return goodMatches;
}

std::vector<cv::DMatch> FaceMatcher::filterGoodMatches(const std::vector<std::vector<cv::DMatch>>& knnMatches) {
    std::vector<cv::DMatch> goodMatches;
    
    for (const auto& matchPair : knnMatches) {
        if (matchPair.size() == 2) {
            // Lowe's ratio test
            if (matchPair[0].distance < maxDistanceRatio * matchPair[1].distance) {
                goodMatches.push_back(matchPair[0]);
            }
        }
    }
    
    return goodMatches;
}

int FaceMatcher::verifyGeometry(const std::vector<cv::KeyPoint>& keypoints1, 
                               const std::vector<cv::KeyPoint>& keypoints2,
                               const std::vector<cv::DMatch>& matches) {
    if (matches.size() < 4) { // RANSACì—ëŠ” ìµœì†Œ 4ê°œì˜ ì ì´ í•„ìš”
        return matches.size();
    }
    
    try {
        // ë§¤ì¹­ëœ ì ë“¤ ì¶”ì¶œ
        std::vector<cv::Point2f> points1, points2;
        for (const auto& match : matches) {
            points1.push_back(keypoints1[match.queryIdx].pt);
            points2.push_back(keypoints2[match.trainIdx].pt);
        }
        
        // RANSACì„ ì‚¬ìš©í•˜ì—¬ í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì • ë° inlier ì°¾ê¸°
        cv::Mat mask;
        cv::findHomography(points1, points2, cv::RANSAC, 3.0, mask);
        
        // inlier ê°œìˆ˜ ì„¸ê¸°
        int inlierCount = 0;
        if (!mask.empty()) {
            for (int i = 0; i < mask.rows; ++i) {
                if (mask.at<uchar>(i) > 0) {
                    inlierCount++;
                }
            }
        }
        
        return inlierCount;
    } catch (const cv::Exception& e) {
        std::cerr << "âŒ ê¸°í•˜í•™ì  ê²€ì¦ ì—ëŸ¬: " << e.what() << std::endl;
        return 0;
    }
}

double FaceMatcher::calculateMatchScore(int goodMatches, int totalKeypoints) {
    if (totalKeypoints == 0) return 0.0;
    
    // ë§¤ì¹­ ë¹„ìœ¨ ê³„ì‚°
    double matchRatio = static_cast<double>(goodMatches) / totalKeypoints;
    
    // ìµœì†Œ ë§¤ì¹­ ê°œìˆ˜ ì¡°ê±´ í™•ì¸
    if (goodMatches < minMatchCount) {
        matchRatio *= 0.5; // í˜ë„í‹° ì ìš©
    }
    
    // 0-1 ë²”ìœ„ë¡œ í´ë¨í•‘
    return std::min(1.0, std::max(0.0, matchRatio));
}

cv::Mat FaceMatcher::preprocessFace(const cv::Mat& face) {
    cv::Mat processed;
    
    // í¬ê¸° ì •ê·œí™”
    cv::resize(face, processed, cv::Size(200, 200));
    
    // ì¡°ëª… ë³´ì • (CLAHE)
    cv::Mat lab;
    cv::cvtColor(processed, lab, cv::COLOR_BGR2Lab);
    std::vector<cv::Mat> labChannels;
    cv::split(lab, labChannels);
    
    cv::Ptr<cv::CLAHE> clahe = cv::createCLAHE(2.0, cv::Size(8, 8));
    clahe->apply(labChannels[0], labChannels[0]);
    
    cv::merge(labChannels, lab);
    cv::cvtColor(lab, processed, cv::COLOR_Lab2BGR);
    
    // ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
    cv::GaussianBlur(processed, processed, cv::Size(3, 3), 0.5);
    
    return processed;
}

void FaceMatcher::drawMatchResult(cv::Mat& frame, const cv::Rect& faceRect, 
                                 double matchScore, bool isMatch, int matchCount) {
    // ë§¤ì¹­ ê²°ê³¼ì— ë”°ë¥¸ ìƒ‰ìƒ ê²°ì •
    cv::Scalar color = isMatch ? cv::Scalar(0, 0, 255) : cv::Scalar(0, 255, 255); // ë¹¨ê°• or ë…¸ë‘
    int thickness = isMatch ? 4 : 2;
    
    // ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
    cv::rectangle(frame, faceRect, color, thickness);
    
    // ë§¤ì¹­ ì •ë³´ í‘œì‹œ
    std::string scoreText = std::to_string(int(matchScore * 100)) + "% (" + std::to_string(matchCount) + ")";
    if (isMatch) {
        scoreText = "MATCH " + scoreText;
    }
    
    cv::Point textPos(faceRect.x, faceRect.y - 10);
    cv::putText(frame, scoreText, textPos, cv::FONT_HERSHEY_SIMPLEX, 
               0.6, color, 2);
    
    // ë§¤ì¹­ëœ ê²½ìš° ì¶”ê°€ í‘œì‹œ
    if (isMatch) {
        // ì›í˜• í…Œë‘ë¦¬ ì¶”ê°€
        cv::Point center(faceRect.x + faceRect.width/2, faceRect.y + faceRect.height/2);
        int radius = std::max(faceRect.width, faceRect.height) / 2 + 10;
        cv::circle(frame, center, radius, cv::Scalar(0, 0, 255), 3);
        
        // "FEATURE MATCHED!" í…ìŠ¤íŠ¸
        cv::putText(frame, "FEATURE MATCHED!", 
                   cv::Point(faceRect.x, faceRect.y + faceRect.height + 25),
                   cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 0, 255), 2);
    }
}

void FaceMatcher::drawFeatureMatches(const cv::Mat& detectedFace, const std::vector<cv::KeyPoint>& keypoints, 
                                   const std::vector<cv::DMatch>& goodMatches) {
    // íŠ¹ì§•ì  ë§¤ì¹­ ì‹œê°í™” (ë””ë²„ê¹…ìš©)
    cv::Mat matchImg;
    cv::drawMatches(referenceFaceImage, referenceKeypoints, detectedFace, keypoints,
                   goodMatches, matchImg, cv::Scalar::all(-1), cv::Scalar::all(-1),
                   std::vector<char>(), cv::DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);
    
    cv::imshow("Feature Matches", matchImg);
}

void FaceMatcher::printMatchingInfo(int totalMatches, int goodMatches, double score) {
    std::cout << "ğŸ” ë§¤ì¹­ ì •ë³´: ì „ì²´=" << totalMatches 
              << ", ê²€ì¦ë¨=" << goodMatches 
              << ", ì ìˆ˜=" << std::fixed << std::setprecision(3) << score << std::endl;
}

// ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ êµ¬í˜„
namespace FeatureMatchingUtils {
    cv::Ptr<cv::Feature2D> createFeatureDetector(const std::string& type) {
        if (type == "SIFT") {
            return cv::SIFT::create(500); // ìµœëŒ€ 500ê°œ íŠ¹ì§•ì 
        } else if (type == "ORB") {
            return cv::ORB::create(500, 1.2f, 8, 31, 0, 2, cv::ORB::HARRIS_SCORE, 31, 20);
        } else {
            std::cerr << "âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŠ¹ì§•ì  ê²€ì¶œê¸°: " << type << std::endl;
            return cv::SIFT::create(500); // ê¸°ë³¸ê°’ìœ¼ë¡œ SIFT ì‚¬ìš©
        }
    }
    
    cv::Ptr<cv::DescriptorMatcher> createDescriptorMatcher(const std::string& type, const std::string& detectorType) {
        if (type == "BF") {
            if (detectorType == "SIFT") {
                return cv::BFMatcher::create(cv::NORM_L2);
            } else { // ORB
                return cv::BFMatcher::create(cv::NORM_HAMMING);
            }
        } else if (type == "FLANN") {
            if (detectorType == "SIFT") {
                return cv::FlannBasedMatcher::create();
            } else {
                // ORBìš© FLANN ì„¤ì •
                auto indexParams = cv::makePtr<cv::flann::LshIndexParams>(6, 12, 1);
                auto searchParams = cv::makePtr<cv::flann::SearchParams>(50);
                return cv::makePtr<cv::FlannBasedMatcher>(indexParams, searchParams);
            }
        } else {
            std::cerr << "âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë§¤ì²˜ íƒ€ì…: " << type << std::endl;
            return cv::BFMatcher::create();
        }
    }
    
    cv::Mat resizeImage(const cv::Mat& image, int targetWidth) {
        if (image.empty()) return cv::Mat();
        
        double aspectRatio = (double)image.rows / image.cols;
        int targetHeight = static_cast<int>(targetWidth * aspectRatio);
        
        cv::Mat resized;
        cv::resize(image, resized, cv::Size(targetWidth, targetHeight));
        return resized;
    }
    
    cv::Rect expandFaceRect(const cv::Rect& face, const cv::Size& imageSize, double factor) {
        int newWidth = static_cast<int>(face.width * factor);
        int newHeight = static_cast<int>(face.height * factor);
        
        int newX = face.x - (newWidth - face.width) / 2;
        int newY = face.y - (newHeight - face.height) / 2;
        
        // ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ ì œí•œ
        newX = std::max(0, newX);
        newY = std::max(0, newY);
        newWidth = std::min(imageSize.width - newX, newWidth);
        newHeight = std::min(imageSize.height - newY, newHeight);
        
        return cv::Rect(newX, newY, newWidth, newHeight);
    }
    
    double scoreToPercent(double score) {
        return std::max(0.0, std::min(100.0, score * 100.0));
    }
    
    double calculateFeatureDensity(const std::vector<cv::KeyPoint>& keypoints, const cv::Size& imageSize) {
        if (keypoints.empty() || imageSize.area() == 0) return 0.0;
        return static_cast<double>(keypoints.size()) / imageSize.area();
    }
}