#include "face_matcher.h"
#include <algorithm>
#include <cmath>
#include <iomanip>

FaceMatcher::FaceMatcher() 
    : videoSource(""), isVideoFile(false), cascadeLoaded(false),
      matchThreshold(0.7), detectorType("SIFT"), matcherType("BF"),
      minMatchCount(10), maxDistanceRatio(0.75) {
    
    // OpenCVÏùò ÏÇ¨Ï†Ñ ÌõàÎ†®Îêú ÏñºÍµ¥ Í≤ÄÏ∂úÍ∏∞ Î°úÎìú
    std::vector<std::string> cascadePaths = {
        "/usr/share/opencv4/haarcascades/haarcascade_frontalface_alt.xml",
        "/usr/local/share/opencv4/haarcascades/haarcascade_frontalface_alt.xml",
        "/usr/share/opencv4/haarcascades/haarcascade_frontalface_default.xml",
        "/usr/local/share/opencv4/haarcascades/haarcascade_frontalface_default.xml",
        "./haarcascades/haarcascade_frontalface_alt.xml",
        "./haarcascades/haarcascade_frontalface_default.xml",
        "haarcascade_frontalface_alt.xml",
        "haarcascade_frontalface_default.xml"
    };
    
    for (const auto& path : cascadePaths) {
        if (faceClassifier.load(path)) {
            cascadeLoaded = true;
            std::cout << "‚úÖ ÏñºÍµ¥ Í≤ÄÏ∂úÍ∏∞ Î°úÎìú ÏÑ±Í≥µ: " << path << std::endl;
            break;
        }
    }
    
    if (!cascadeLoaded) {
        std::cerr << "‚ùå ÏñºÍµ¥ Í≤ÄÏ∂úÍ∏∞ Î°úÎìú Ïã§Ìå®! Haar cascade ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§." << std::endl;
        std::cerr << "üìù Ìï¥Í≤∞Î∞©Î≤ï: Haar cascade ÌååÏùºÏùÑ Îã§Ïö¥Î°úÎìúÌïòÍ≥† Project4 Ìè¥ÎçîÏóê Î≥µÏÇ¨ÌïòÏÑ∏Ïöî." << std::endl;
        std::cerr << "   wget https://raw.githubusercontent.com/opencv/opencv/4.x/data/haarcascades/haarcascade_frontalface_default.xml" << std::endl;
    }
    
    // Í∏∞Î≥∏ ÌäπÏßïÏ†ê Í≤ÄÏ∂úÍ∏∞ÏôÄ Îß§Ï≤ò ÏÉùÏÑ±
    detector = FeatureMatchingUtils::createFeatureDetector(detectorType);
    matcher = FeatureMatchingUtils::createDescriptorMatcher(matcherType, detectorType);
    
    std::cout << "üîß ÌäπÏßïÏ†ê Í∏∞Î∞ò ÏñºÍµ¥ Îß§Ïπ≠ ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî ÏôÑÎ£å!" << std::endl;
    std::cout << "   - ÌäπÏßïÏ†ê Í≤ÄÏ∂úÍ∏∞: " << detectorType << std::endl;
    std::cout << "   - Îß§Ï≤ò: " << matcherType << std::endl;
    std::cout << "   - ÏµúÏÜå Îß§Ïπ≠ Í∞úÏàò: " << minMatchCount << std::endl;
}

FaceMatcher::~FaceMatcher() {
    if (videoCapture.isOpened()) {
        videoCapture.release();
    }
}

bool FaceMatcher::loadReferenceFace(const std::string& imagePath) {
    referenceFaceImage = cv::imread(imagePath, cv::IMREAD_COLOR);
    if (referenceFaceImage.empty()) {
        std::cerr << "‚ùå Í∏∞Ï§Ä ÏñºÍµ¥ Ïù¥ÎØ∏ÏßÄÎ•º Î°úÎìúÌï† Ïàò ÏóÜÏäµÎãàÎã§: " << imagePath << std::endl;
        return false;
    }
    
    // ÏñºÍµ¥ Í≤ÄÏ∂ú
    std::vector<cv::Rect> faces = detectFaces(referenceFaceImage);
    if (faces.empty()) {
        std::cerr << "‚ùå Í∏∞Ï§Ä Ïù¥ÎØ∏ÏßÄÏóêÏÑú ÏñºÍµ¥ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§!" << std::endl;
        return false;
    }
    
    // Í∞ÄÏû• ÌÅ∞ ÏñºÍµ¥ÏùÑ Í∏∞Ï§ÄÏúºÎ°ú ÏÑ†ÌÉù
    cv::Rect largestFace = *std::max_element(faces.begin(), faces.end(), 
        [](const cv::Rect& a, const cv::Rect& b) {
            return a.area() < b.area();
        });
    
    // ÏñºÍµ¥ ÏòÅÏó≠ ÌôïÏû• Î∞è Ï∂îÏ∂ú
    cv::Rect expandedFace = FeatureMatchingUtils::expandFaceRect(largestFace, referenceFaceImage.size());
    cv::Mat faceROI = referenceFaceImage(expandedFace).clone();
    
    // Ï†ÑÏ≤òÎ¶¨
    faceROI = preprocessFace(faceROI);
    
    // Í∏∞Ï§Ä ÏñºÍµ¥ÏóêÏÑú ÌäπÏßïÏ†ê Ï∂îÏ∂ú
    extractFeatures(faceROI, referenceKeypoints, referenceDescriptors);
    
    if (referenceKeypoints.empty()) {
        std::cerr << "‚ùå Í∏∞Ï§Ä ÏñºÍµ¥ÏóêÏÑú ÌäπÏßïÏ†êÏùÑ Ï∂îÏ∂úÌï† Ïàò ÏóÜÏäµÎãàÎã§!" << std::endl;
        return false;
    }
    
    double featureDensity = FeatureMatchingUtils::calculateFeatureDensity(referenceKeypoints, faceROI.size());
    
    std::cout << "‚úÖ Í∏∞Ï§Ä ÏñºÍµ¥ ÌäπÏßïÏ†ê Ï∂îÏ∂ú ÏôÑÎ£å!" << std::endl;
    std::cout << "   - Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞: " << faceROI.size() << std::endl;
    std::cout << "   - ÌäπÏßïÏ†ê Í∞úÏàò: " << referenceKeypoints.size() << std::endl;
    std::cout << "   - ÌäπÏßïÏ†ê Î∞ÄÎèÑ: " << std::fixed << std::setprecision(4) << featureDensity << " points/pixel¬≤" << std::endl;
    
    return true;
}

bool FaceMatcher::startWebcam(int deviceId) {
    videoCapture.open(deviceId);
    if (!videoCapture.isOpened()) {
        std::cerr << "‚ùå ÏõπÏ∫†ÏùÑ Ïó¥ Ïàò ÏóÜÏäµÎãàÎã§! (Device ID: " << deviceId << ")" << std::endl;
        return false;
    }
    
    // ÏõπÏ∫† ÏÑ§Ï†ï
    videoCapture.set(cv::CAP_PROP_FRAME_WIDTH, 640);
    videoCapture.set(cv::CAP_PROP_FRAME_HEIGHT, 480);
    videoCapture.set(cv::CAP_PROP_FPS, 30);
    
    videoSource = "webcam";
    isVideoFile = false;
    
    std::cout << "‚úÖ ÏõπÏ∫† ÏãúÏûë ÏôÑÎ£å!" << std::endl;
    return true;
}

bool FaceMatcher::loadVideoFile(const std::string& videoPath) {
    videoCapture.open(videoPath);
    if (!videoCapture.isOpened()) {
        std::cerr << "‚ùå ÎπÑÎîîÏò§ ÌååÏùºÏùÑ Ïó¥ Ïàò ÏóÜÏäµÎãàÎã§: " << videoPath << std::endl;
        return false;
    }
    
    videoSource = videoPath;
    isVideoFile = true;
    
    // ÎπÑÎîîÏò§ Ï†ïÎ≥¥ Ï∂úÎ†•
    int totalFrames = static_cast<int>(videoCapture.get(cv::CAP_PROP_FRAME_COUNT));
    double fps = videoCapture.get(cv::CAP_PROP_FPS);
    int width = static_cast<int>(videoCapture.get(cv::CAP_PROP_FRAME_WIDTH));
    int height = static_cast<int>(videoCapture.get(cv::CAP_PROP_FRAME_HEIGHT));
    
    std::cout << "‚úÖ ÎπÑÎîîÏò§ ÌååÏùº Î°úÎìú ÏôÑÎ£å!" << std::endl;
    std::cout << "üìÅ ÌååÏùº: " << videoPath << std::endl;
    std::cout << "üìä Ï†ïÎ≥¥: " << width << "x" << height << ", " << fps << " FPS, " << totalFrames << " ÌîÑÎ†àÏûÑ" << std::endl;
    
    return true;
}

void FaceMatcher::runFaceMatching() {
    if (!videoCapture.isOpened()) {
        std::cerr << "‚ùå ÎπÑÎîîÏò§ ÏÜåÏä§Í∞Ä Ïó¥Î†§ÏûàÏßÄ ÏïäÏäµÎãàÎã§!" << std::endl;
        return;
    }
    
    if (referenceKeypoints.empty() || referenceDescriptors.empty()) {
        std::cerr << "‚ùå Í∏∞Ï§Ä ÏñºÍµ¥ ÌäπÏßïÏ†êÏù¥ Ï§ÄÎπÑÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§!" << std::endl;
        return;
    }
    
    std::string sourceType = isVideoFile ? "ÎπÑÎîîÏò§ ÌååÏùº" : "ÏõπÏ∫†";
    std::cout << "üé• " << sourceType << " ÌäπÏßïÏ†ê Îß§Ïπ≠ ÏãúÏûë!" << std::endl;
    if (isVideoFile) {
        std::cout << "üìÅ ÌååÏùº: " << videoSource << std::endl;
    }
    
    std::cout << "üìã Ï°∞ÏûëÎ≤ï:" << std::endl;
    std::cout << "   - ESC ÎòêÎäî 'q': Ï¢ÖÎ£å" << std::endl;
    std::cout << "   - SPACE: ÏùºÏãúÏ†ïÏßÄ/Ïû¨ÏÉù (ÎπÑÎîîÏò§ ÌååÏùº)" << std::endl;
    std::cout << "   - 't': Îß§Ïπ≠ ÏûÑÍ≥ÑÍ∞í Ï°∞Ï†ï" << std::endl;
    std::cout << "   - 's': Ïä§ÌÅ¨Î¶∞ÏÉ∑ Ï†ÄÏû•" << std::endl;
    std::cout << "   - 'd': ÌäπÏßïÏ†ê Í≤ÄÏ∂úÍ∏∞ Î≥ÄÍ≤Ω (SIFT ‚Üî ORB)" << std::endl;
    std::cout << std::endl;
    
    cv::Mat frame;
    int frameCount = 0;
    int totalFrames = isVideoFile ? static_cast<int>(videoCapture.get(cv::CAP_PROP_FRAME_COUNT)) : 0;
    bool paused = false;
    
    while (true) {
        if (!paused || !isVideoFile) {
            videoCapture >> frame;
            if (frame.empty()) {
                if (isVideoFile) {
                    std::cout << "üìπ ÎπÑÎîîÏò§ Ïû¨ÏÉù ÏôÑÎ£å!" << std::endl;
                }
                break;
            }
            frameCount++;
        }
        
        // ÏñºÍµ¥ Í≤ÄÏ∂ú
        std::vector<cv::Rect> faces = detectFaces(frame);
        
        // Í∞Å Í≤ÄÏ∂úÎêú ÏñºÍµ¥Ïóê ÎåÄÌï¥ ÌäπÏßïÏ†ê Îß§Ïπ≠ ÏàòÌñâ
        for (const auto& faceRect : faces) {
            // ÏñºÍµ¥ ÏòÅÏó≠ ÌôïÏû• Î∞è Ï∂îÏ∂ú
            cv::Rect expandedFace = FeatureMatchingUtils::expandFaceRect(faceRect, frame.size());
            cv::Mat detectedFace = frame(expandedFace);
            
            // ÌäπÏßïÏ†ê Í∏∞Î∞ò ÏñºÍµ¥ Îß§Ïπ≠
            double matchScore = matchFaceByFeatures(detectedFace);
            bool isMatch = matchScore >= matchThreshold;
            
            // Í≤∞Í≥º ÌëúÏãú
            int matchCount = static_cast<int>(matchScore * 100); // ÏûÑÏãúÎ°ú Î∞±Î∂ÑÏú®ÏùÑ Îß§Ïπ≠ Í∞úÏàòÎ°ú ÏÇ¨Ïö©
            drawMatchResult(frame, expandedFace, matchScore, isMatch, matchCount);
        }
        
        // Ï†ïÎ≥¥ ÌëúÏãú
        std::string title = isVideoFile ? "Feature Matching - Video" : "Feature Matching - Webcam";
        cv::putText(frame, title, cv::Point(10, 30), 
                   cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 255, 0), 2);
        
        cv::putText(frame, "Threshold: " + std::to_string(int(matchThreshold * 100)) + "%", 
                   cv::Point(10, 60), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 255, 255), 1);
        cv::putText(frame, "Faces: " + std::to_string(faces.size()), 
                   cv::Point(10, 80), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 255, 255), 1);
        cv::putText(frame, "Detector: " + detectorType, 
                   cv::Point(10, 100), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 255, 255), 1);
        cv::putText(frame, "Ref Features: " + std::to_string(referenceKeypoints.size()), 
                   cv::Point(10, 120), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 255, 255), 1);
        
        // ÎπÑÎîîÏò§ ÌååÏùºÏù∏ Í≤ΩÏö∞ ÌîÑÎ†àÏûÑ Ï†ïÎ≥¥ ÌëúÏãú
        if (isVideoFile) {
            std::string frameInfo = "Frame: " + std::to_string(frameCount) + "/" + std::to_string(totalFrames);
            cv::putText(frame, frameInfo, cv::Point(10, 140), 
                       cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 255, 255), 1);
            
            if (paused) {
                cv::putText(frame, "PAUSED", cv::Point(frame.cols/2 - 50, 50), 
                           cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(0, 255, 255), 3);
            }
        }
        
        // ÌôîÎ©¥ Ï∂úÎ†•
        cv::imshow(title, frame);
        
        // ÌÇ§ ÏûÖÎ†• Ï≤òÎ¶¨
        int waitTime = isVideoFile ? 30 : 1;
        int key = cv::waitKey(waitTime) & 0xFF;
        
        if (key == 27 || key == 'q') { // ESC ÎòêÎäî 'q'
            break;
        } else if (key == ' ' && isVideoFile) { // SPACE - ÏùºÏãúÏ†ïÏßÄ/Ïû¨ÏÉù
            paused = !paused;
            std::cout << (paused ? "‚è∏Ô∏è ÏùºÏãúÏ†ïÏßÄ" : "‚ñ∂Ô∏è Ïû¨ÏÉù") << std::endl;
        } else if (key == 't') { // ÏûÑÍ≥ÑÍ∞í Ï°∞Ï†ï
            std::cout << "ÌòÑÏû¨ ÏûÑÍ≥ÑÍ∞í: " << int(matchThreshold * 100) << "%" << std::endl;
            std::cout << "ÏÉàÎ°úÏö¥ ÏûÑÍ≥ÑÍ∞í ÏûÖÎ†• (0-100): ";
            int newThreshold;
            std::cin >> newThreshold;
            matchThreshold = std::max(0, std::min(100, newThreshold)) / 100.0;
            std::cout << "ÏûÑÍ≥ÑÍ∞í Î≥ÄÍ≤Ω: " << int(matchThreshold * 100) << "%" << std::endl;
        } else if (key == 's') { // Ïä§ÌÅ¨Î¶∞ÏÉ∑
            std::string filename = "screenshot_" + std::to_string(frameCount) + ".jpg";
            cv::imwrite(filename, frame);
            std::cout << "üì∏ Ïä§ÌÅ¨Î¶∞ÏÉ∑ Ï†ÄÏû•: " << filename << std::endl;
        } else if (key == 'd') { // ÌäπÏßïÏ†ê Í≤ÄÏ∂úÍ∏∞ Î≥ÄÍ≤Ω
            detectorType = (detectorType == "SIFT") ? "ORB" : "SIFT";
            detector = FeatureMatchingUtils::createFeatureDetector(detectorType);
            matcher = FeatureMatchingUtils::createDescriptorMatcher(matcherType, detectorType);
            
            // Í∏∞Ï§Ä ÏñºÍµ¥ ÌäπÏßïÏ†ê Ïû¨Ï∂îÏ∂ú
            if (!referenceFaceImage.empty()) {
                std::vector<cv::Rect> faces = detectFaces(referenceFaceImage);
                if (!faces.empty()) {
                    cv::Rect largestFace = *std::max_element(faces.begin(), faces.end(), 
                        [](const cv::Rect& a, const cv::Rect& b) { return a.area() < b.area(); });
                    cv::Rect expandedFace = FeatureMatchingUtils::expandFaceRect(largestFace, referenceFaceImage.size());
                    cv::Mat faceROI = preprocessFace(referenceFaceImage(expandedFace));
                    extractFeatures(faceROI, referenceKeypoints, referenceDescriptors);
                }
            }
            
            std::cout << "üîÑ ÌäπÏßïÏ†ê Í≤ÄÏ∂úÍ∏∞ Î≥ÄÍ≤Ω: " << detectorType << " (Í∏∞Ï§Ä ÌäπÏßïÏ†ê: " << referenceKeypoints.size() << "Í∞ú)" << std::endl;
        }
    }
    
    cv::destroyAllWindows();
    std::cout << "üëã ÌäπÏßïÏ†ê Îß§Ïπ≠ Ï¢ÖÎ£å!" << std::endl;
}

void FaceMatcher::runVideoFaceMatching() {
    runFaceMatching();
}

std::vector<cv::Rect> FaceMatcher::detectFaces(const cv::Mat& frame) {
    std::vector<cv::Rect> faces;
    
    if (!cascadeLoaded || faceClassifier.empty()) {
        static bool errorShown = false;
        if (!errorShown) {
            std::cerr << "‚ö†Ô∏è ÏñºÍµ¥ Í≤ÄÏ∂úÍ∏∞Í∞Ä Î°úÎìúÎêòÏßÄ ÏïäÏïÑ ÏñºÍµ¥ Í≤ÄÏ∂úÏùÑ ÏàòÌñâÌï† Ïàò ÏóÜÏäµÎãàÎã§." << std::endl;
            errorShown = true;
        }
        return faces;
    }
    
    if (frame.empty()) {
        std::cerr << "‚ö†Ô∏è Îπà ÌîÑÎ†àÏûÑÏù¥ ÏûÖÎ†•ÎêòÏóàÏäµÎãàÎã§." << std::endl;
        return faces;
    }
    
    cv::Mat grayFrame;
    try {
        if (frame.channels() == 3) {
            cv::cvtColor(frame, grayFrame, cv::COLOR_BGR2GRAY);
        } else {
            grayFrame = frame.clone();
        }
        
        cv::equalizeHist(grayFrame, grayFrame);
        
        faceClassifier.detectMultiScale(
            grayFrame,
            faces,
            1.1,
            3,
            0 | cv::CASCADE_SCALE_IMAGE,
            cv::Size(30, 30),
            cv::Size()
        );
        
    } catch (const cv::Exception& e) {
        std::cerr << "‚ùå detectMultiScale ÏóêÎü¨: " << e.what() << std::endl;
    }
    
    return faces;
}

double FaceMatcher::matchFaceByFeatures(const cv::Mat& detectedFace) {
    if (detectedFace.empty() || referenceDescriptors.empty()) {
        return 0.0;
    }
    
    // Ï†ÑÏ≤òÎ¶¨
    cv::Mat processedFace = preprocessFace(detectedFace);
    
    // ÌäπÏßïÏ†ê Ï∂îÏ∂ú
    std::vector<cv::KeyPoint> detectedKeypoints;
    cv::Mat detectedDescriptors;
    extractFeatures(processedFace, detectedKeypoints, detectedDescriptors);
    
    if (detectedKeypoints.empty() || detectedDescriptors.empty()) {
        return 0.0;
    }
    
    // ÏµúÍ∑ºÏ†ë Îß§Ïπ≠
    std::vector<cv::DMatch> matches = findNearestMatches(referenceDescriptors, detectedDescriptors);
    
    if (matches.empty()) {
        return 0.0;
    }
    
    // Í∏∞ÌïòÌïôÏ†Å Í≤ÄÏ¶ù
    int verifiedMatches = verifyGeometry(referenceKeypoints, detectedKeypoints, matches);
    
    // Îß§Ïπ≠ Ï†êÏàò Í≥ÑÏÇ∞
    double score = calculateMatchScore(verifiedMatches, referenceKeypoints.size());
    
    // ÎîîÎ≤ÑÍ∑∏ Ï†ïÎ≥¥ Ï∂úÎ†• (Í∞úÎ∞ú ÏãúÏóêÎßå)
    static int debugCount = 0;
    if (debugCount++ % 30 == 0) { // 30ÌîÑÎ†àÏûÑÎßàÎã§ Ìïú Î≤àÏî©
        printMatchingInfo(matches.size(), verifiedMatches, score);
    }
    
    return score;
}

void FaceMatcher::extractFeatures(const cv::Mat& image, std::vector<cv::KeyPoint>& keypoints, cv::Mat& descriptors) {
    if (!detector) {
        std::cerr << "‚ùå ÌäπÏßïÏ†ê Í≤ÄÏ∂úÍ∏∞Í∞Ä Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§!" << std::endl;
        return;
    }
    
    try {
        detector->detectAndCompute(image, cv::noArray(), keypoints, descriptors);
    } catch (const cv::Exception& e) {
        std::cerr << "‚ùå ÌäπÏßïÏ†ê Ï∂îÏ∂ú ÏóêÎü¨: " << e.what() << std::endl;
        keypoints.clear();
        descriptors = cv::Mat();
    }
}

std::vector<cv::DMatch> FaceMatcher::findNearestMatches(const cv::Mat& descriptors1, const cv::Mat& descriptors2) {
    std::vector<cv::DMatch> goodMatches;
    
    if (!matcher || descriptors1.empty() || descriptors2.empty()) {
        return goodMatches;
    }
    
    try {
        if (detectorType == "SIFT") {
            // SIFTÏùò Í≤ΩÏö∞ k-NN Îß§Ïπ≠ ÏÇ¨Ïö© (Lowe's ratio test)
            std::vector<std::vector<cv::DMatch>> knnMatches;
            matcher->knnMatch(descriptors1, descriptors2, knnMatches, 2);
            goodMatches = filterGoodMatches(knnMatches);
        } else {
            // ORBÏùò Í≤ΩÏö∞ Îã®Ïàú Îß§Ïπ≠ ÌõÑ Í±∞Î¶¨ Í∏∞Î∞ò ÌïÑÌÑ∞ÎßÅ
            std::vector<cv::DMatch> matches;
            matcher->match(descriptors1, descriptors2, matches);
            
            // Í±∞Î¶¨ Í∏∞Î∞ò ÌïÑÌÑ∞ÎßÅ
            double maxDist = 0; double minDist = 100;
            for (const auto& match : matches) {
                double dist = match.distance;
                if (dist < minDist) minDist = dist;
                if (dist > maxDist) maxDist = dist;
            }
            
            double threshold = std::max(2 * minDist, 30.0);
            for (const auto& match : matches) {
                if (match.distance <= threshold) {
                    goodMatches.push_back(match);
                }
            }
        }
    } catch (const cv::Exception& e) {
        std::cerr << "‚ùå ÌäπÏßïÏ†ê Îß§Ïπ≠ ÏóêÎü¨: " << e.what() << std::endl;
    }
    
    return goodMatches;
}

std::vector<cv::DMatch> FaceMatcher::filterGoodMatches(const std::vector<std::vector<cv::DMatch>>& knnMatches) {
    std::vector<cv::DMatch> goodMatches;
    
    for (const auto& matchPair : knnMatches) {
        if (matchPair.size() == 2) {
            // Lowe's ratio test
            if (matchPair[0].distance < maxDistanceRatio * matchPair[1].distance) {
                goodMatches.push_back(matchPair[0]);
            }
        }
    }
    
    return goodMatches;
}

int FaceMatcher::verifyGeometry(const std::vector<cv::KeyPoint>& keypoints1, 
                               const std::vector<cv::KeyPoint>& keypoints2,
                               const std::vector<cv::DMatch>& matches) {
    if (matches.size() < 4) { // RANSACÏóêÎäî ÏµúÏÜå 4Í∞úÏùò Ï†êÏù¥ ÌïÑÏöî
        return matches.size();
    }
    
    try {
        // Îß§Ïπ≠Îêú Ï†êÎì§ Ï∂îÏ∂ú
        std::vector<cv::Point2f> points1, points2;
        for (const auto& match : matches) {
            points1.push_back(keypoints1[match.queryIdx].pt);
            points2.push_back(keypoints2[match.trainIdx].pt);
        }
        
        // RANSACÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Ìò∏Î™®Í∑∏ÎûòÌîº Ï∂îÏ†ï Î∞è inlier Ï∞æÍ∏∞
        cv::Mat mask;
        cv::findHomography(points1, points2, cv::RANSAC, 3.0, mask);
        
        // inlier Í∞úÏàò ÏÑ∏Í∏∞
        int inlierCount = 0;
        if (!mask.empty()) {
            for (int i = 0; i < mask.rows; ++i) {
                if (mask.at<uchar>(i) > 0) {
                    inlierCount++;
                }
            }
        }
        
        return inlierCount;
    } catch (const cv::Exception& e) {
        std::cerr << "‚ùå Í∏∞ÌïòÌïôÏ†Å Í≤ÄÏ¶ù ÏóêÎü¨: " << e.what() << std::endl;
        return 0;
    }
}

double FaceMatcher::calculateMatchScore(int goodMatches, int totalKeypoints) {
    if (totalKeypoints == 0) return 0.0;
    
    // Îß§Ïπ≠ ÎπÑÏú® Í≥ÑÏÇ∞
    double matchRatio = static_cast<double>(goodMatches) / totalKeypoints;
    
    // ÏµúÏÜå Îß§Ïπ≠ Í∞úÏàò Ï°∞Í±¥ ÌôïÏù∏
    if (goodMatches < minMatchCount) {
        matchRatio *= 0.5; // ÌéòÎÑêÌã∞ Ï†ÅÏö©
    }
    
    // 0-1 Î≤îÏúÑÎ°ú ÌÅ¥Îû®Ìïë
    return std::min(1.0, std::max(0.0, matchRatio));
}

cv::Mat FaceMatcher::preprocessFace(const cv::Mat& face) {
    cv::Mat processed;
    
    // ÌÅ¨Í∏∞ Ï†ïÍ∑úÌôî
    cv::resize(face, processed, cv::Size(200, 200));
    
    // Ï°∞Î™Ö Î≥¥Ï†ï (CLAHE)
    cv::Mat lab;
    cv::cvtColor(processed, lab, cv::COLOR_BGR2Lab);
    std::vector<cv::Mat> labChannels;
    cv::split(lab, labChannels);
    
    cv::Ptr<cv::CLAHE> clahe = cv::createCLAHE(2.0, cv::Size(8, 8));
    clahe->apply(labChannels[0], labChannels[0]);
    
    cv::merge(labChannels, lab);
    cv::cvtColor(lab, processed, cv::COLOR_Lab2BGR);
    
    // Í∞ÄÏö∞ÏãúÏïà Î∏îÎü¨Î°ú ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞
    cv::GaussianBlur(processed, processed, cv::Size(3, 3), 0.5);
    
    return processed;
}

void FaceMatcher::drawMatchResult(cv::Mat& frame, const cv::Rect& faceRect, 
                                 double matchScore, bool isMatch, int matchCount) {
    // Îß§Ïπ≠ Í≤∞Í≥ºÏóê Îî∞Î•∏ ÏÉâÏÉÅ Í≤∞Ï†ï
    cv::Scalar color = isMatch ? cv::Scalar(0, 0, 255) : cv::Scalar(0, 255, 255); // Îπ®Í∞ï or ÎÖ∏Îûë
    int thickness = isMatch ? 4 : 2;
    
    // ÏÇ¨Í∞ÅÌòï Í∑∏Î¶¨Í∏∞
    cv::rectangle(frame, faceRect, color, thickness);
    
    // Îß§Ïπ≠ Ï†ïÎ≥¥ ÌëúÏãú
    std::string scoreText = std::to_string(int(matchScore * 100)) + "% (" + std::to_string(matchCount) + ")";
    if (isMatch) {
        scoreText = "MATCH " + scoreText;
    }
    
    cv::Point textPos(faceRect.x, faceRect.y - 10);
    cv::putText(frame, scoreText, textPos, cv::FONT_HERSHEY_SIMPLEX, 
               0.6, color, 2);
    
    // Îß§Ïπ≠Îêú Í≤ΩÏö∞ Ï∂îÍ∞Ä ÌëúÏãú
    if (isMatch) {
        // ÏõêÌòï ÌÖåÎëêÎ¶¨ Ï∂îÍ∞Ä
        cv::Point center(faceRect.x + faceRect.width/2, faceRect.y + faceRect.height/2);
        int radius = std::max(faceRect.width, faceRect.height) / 2 + 10;
        cv::circle(frame, center, radius, cv::Scalar(0, 0, 255), 3);
        
        // "FEATURE MATCHED!" ÌÖçÏä§Ìä∏
        cv::putText(frame, "FEATURE MATCHED!", 
                   cv::Point(faceRect.x, faceRect.y + faceRect.height + 25),
                   cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 0, 255), 2);
    }
}

void FaceMatcher::drawFeatureMatches(const cv::Mat& detectedFace, const std::vector<cv::KeyPoint>& keypoints, 
                                   const std::vector<cv::DMatch>& goodMatches) {
    // ÌäπÏßïÏ†ê Îß§Ïπ≠ ÏãúÍ∞ÅÌôî (ÎîîÎ≤ÑÍπÖÏö©)
    cv::Mat matchImg;
    cv::drawMatches(referenceFaceImage, referenceKeypoints, detectedFace, keypoints,
                   goodMatches, matchImg, cv::Scalar::all(-1), cv::Scalar::all(-1),
                   std::vector<char>(), cv::DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);
    
    cv::imshow("Feature Matches", matchImg);
}

void FaceMatcher::printMatchingInfo(int totalMatches, int goodMatches, double score) {
    std::cout << "üîç Îß§Ïπ≠ Ï†ïÎ≥¥: Ï†ÑÏ≤¥=" << totalMatches 
              << ", Í≤ÄÏ¶ùÎê®=" << goodMatches 
              << ", Ï†êÏàò=" << std::fixed << std::setprecision(3) << score << std::endl;
}

// Ïú†Ìã∏Î¶¨Ìã∞ Ìï®ÏàòÎì§ Íµ¨ÌòÑ
namespace FeatureMatchingUtils {
    cv::Ptr<cv::Feature2D> createFeatureDetector(const std::string& type) {
        if (type == "SIFT") {
            return cv::SIFT::create(500); // ÏµúÎåÄ 500Í∞ú ÌäπÏßïÏ†ê
        } else if (type == "ORB") {
            return cv::ORB::create(500, 1.2f, 8, 31, 0, 2, cv::ORB::HARRIS_SCORE, 31, 20);
        } else {
            std::cerr << "‚ùå ÏßÄÏõêÌïòÏßÄ ÏïäÎäî ÌäπÏßïÏ†ê Í≤ÄÏ∂úÍ∏∞: " << type << std::endl;
            return cv::SIFT::create(500); // Í∏∞Î≥∏Í∞íÏúºÎ°ú SIFT ÏÇ¨Ïö©
        }
    }
    
    cv::Ptr<cv::DescriptorMatcher> createDescriptorMatcher(const std::string& type, const std::string& detectorType) {
        if (type == "BF") {
            if (detectorType == "SIFT") {
                return cv::BFMatcher::create(cv::NORM_L2);
            } else { // ORB
                return cv::BFMatcher::create(cv::NORM_HAMMING);
            }
        } else if (type == "FLANN") {
            if (detectorType == "SIFT") {
                return cv::FlannBasedMatcher::create();
            } else {
                // ORBÏö© FLANN ÏÑ§Ï†ï
                auto indexParams = cv::makePtr<cv::flann::LshIndexParams>(6, 12, 1);
                auto searchParams = cv::makePtr<cv::flann::SearchParams>(50);
                return cv::makePtr<cv::FlannBasedMatcher>(indexParams, searchParams);
            }
        } else {
            std::cerr << "‚ùå ÏßÄÏõêÌïòÏßÄ ÏïäÎäî Îß§Ï≤ò ÌÉÄÏûÖ: " << type << std::endl;
            return cv::BFMatcher::create();
        }
    }
    
    cv::Mat resizeImage(const cv::Mat& image, int targetWidth) {
        if (image.empty()) return cv::Mat();
        
        double aspectRatio = (double)image.rows / image.cols;
        int targetHeight = static_cast<int>(targetWidth * aspectRatio);
        
        cv::Mat resized;
        cv::resize(image, resized, cv::Size(targetWidth, targetHeight));
        return resized;
    }
    
    cv::Rect expandFaceRect(const cv::Rect& face, const cv::Size& imageSize, double factor) {
        int newWidth = static_cast<int>(face.width * factor);
        int newHeight = static_cast<int>(face.height * factor);
        
        int newX = face.x - (newWidth - face.width) / 2;
        int newY = face.y - (newHeight - face.height) / 2;
        
        // Ïù¥ÎØ∏ÏßÄ Í≤ΩÍ≥Ñ ÎÇ¥Î°ú Ï†úÌïú
        newX = std::max(0, newX);
        newY = std::max(0, newY);
        newWidth = std::min(imageSize.width - newX, newWidth);
        newHeight = std::min(imageSize.height - newY, newHeight);
        
        return cv::Rect(newX, newY, newWidth, newHeight);
    }
    
    double scoreToPercent(double score) {
        return std::max(0.0, std::min(100.0, score * 100.0));
    }
    
    double calculateFeatureDensity(const std::vector<cv::KeyPoint>& keypoints, const cv::Size& imageSize) {
        if (keypoints.empty() || imageSize.area() == 0) return 0.0;
        return static_cast<double>(keypoints.size()) / imageSize.area();
    }
}