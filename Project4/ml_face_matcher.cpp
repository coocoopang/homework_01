#include "ml_face_matcher.h"
#include <algorithm>
#include <cmath>
#include <chrono>
#include <filesystem>

MLFaceMatcher::MLFaceMatcher() 
    : currentExtractorType(FeatureExtractorType::ORB),
      currentDistanceMetric(DistanceMetric::EUCLIDEAN),
      matchThreshold(0.7),
      knnK(2),
      ratioThreshold(0.7),
      cascadeLoaded(false),
      isVideoFile(false),
      videoSource("") {
    
    initializeFeatureExtractor();
    initializeFaceDetector();
}

MLFaceMatcher::~MLFaceMatcher() {
    if (videoCapture.isOpened()) {
        videoCapture.release();
    }
}

// === ÏÑ§Ï†ï Í¥ÄÎ†® Î©îÏÑúÎìú ===

void MLFaceMatcher::setFeatureExtractor(FeatureExtractorType type) {
    currentExtractorType = type;
    initializeFeatureExtractor();
    std::cout << "üîß ÌäπÏßï Ï∂îÏ∂úÍ∏∞ Î≥ÄÍ≤Ω: ";
    switch (type) {
        case FeatureExtractorType::SIFT:
            std::cout << "SIFT" << std::endl;
            break;
        case FeatureExtractorType::ORB:
            std::cout << "ORB" << std::endl;
            break;
        case FeatureExtractorType::AKAZE:
            std::cout << "AKAZE" << std::endl;
            break;
    }
}

void MLFaceMatcher::setDistanceMetric(DistanceMetric metric) {
    currentDistanceMetric = metric;
    std::cout << "üìè Í±∞Î¶¨ Ï∏°Ï†ï Î∞©Î≤ï Î≥ÄÍ≤Ω: ";
    switch (metric) {
        case DistanceMetric::EUCLIDEAN:
            std::cout << "Ïú†ÌÅ¥Î¶¨Îìú Í±∞Î¶¨" << std::endl;
            break;
        case DistanceMetric::COSINE:
            std::cout << "ÏΩîÏÇ¨Ïù∏ Í±∞Î¶¨" << std::endl;
            break;
        case DistanceMetric::HAMMING:
            std::cout << "Ìï¥Î∞ç Í±∞Î¶¨" << std::endl;
            break;
    }
}

void MLFaceMatcher::setMatchThreshold(double threshold) {
    matchThreshold = threshold;
    std::cout << "üéØ Îß§Ïπ≠ ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ï: " << threshold << std::endl;
}

void MLFaceMatcher::setKNNParameters(int k, double ratioThreshold) {
    knnK = k;
    this->ratioThreshold = ratioThreshold;
    std::cout << "üîç KNN ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï: K=" << k << ", Ratio=" << ratioThreshold << std::endl;
}

// === ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Í¥ÄÎ¶¨ ===

bool MLFaceMatcher::addReferenceFace(const std::string& imagePath, const std::string& label) {
    cv::Mat image = cv::imread(imagePath, cv::IMREAD_COLOR);
    if (image.empty()) {
        std::cerr << "‚ùå Ïù¥ÎØ∏ÏßÄ Î°úÎìú Ïã§Ìå®: " << imagePath << std::endl;
        return false;
    }
    
    MLFaceMatchingUtils::Timer timer;
    timer.start();
    
    // ÏñºÍµ¥ Í≤ÄÏ∂ú
    std::vector<cv::Rect> faces = detectFaces(image);
    if (faces.empty()) {
        std::cerr << "‚ùå ÏñºÍµ¥ Í≤ÄÏ∂ú Ïã§Ìå®: " << imagePath << std::endl;
        return false;
    }
    
    // Í∞ÄÏû• ÌÅ∞ ÏñºÍµ¥ ÏÑ†ÌÉù
    cv::Rect largestFace = *std::max_element(faces.begin(), faces.end(),
        [](const cv::Rect& a, const cv::Rect& b) {
            return a.area() < b.area();
        });
    
    // ÏñºÍµ¥ ÏòÅÏó≠ ÌôïÏû•
    cv::Rect expandedFace = expandFaceRect(largestFace, image.size());
    cv::Mat faceImage = image(expandedFace);
    
    // ÌäπÏßï Ï∂îÏ∂ú
    FaceFeatures features = extractFaceFeatures(faceImage, expandedFace);
    features.label = label;
    
    if (features.descriptors.empty()) {
        std::cerr << "‚ùå ÌäπÏßï Ï∂îÏ∂ú Ïã§Ìå®: " << imagePath << std::endl;
        return false;
    }
    
    referenceFeatures.push_back(features);
    labelCounts[label]++;
    
    double processingTime = timer.getElapsedMs();
    std::cout << "‚úÖ Í∏∞Ï§Ä ÏñºÍµ¥ Ï∂îÍ∞Ä: " << label 
              << " (" << features.keypoints.size() << " ÌäπÏßïÏ†ê, "
              << processingTime << "ms)" << std::endl;
    
    return true;
}

bool MLFaceMatcher::loadMultipleReferences(const std::string& directory) {
    std::vector<std::string> imageFiles = MLFaceMatchingUtils::getImageFiles(directory);
    
    if (imageFiles.empty()) {
        std::cerr << "‚ùå ÎîîÎ†âÌÑ∞Î¶¨ÏóêÏÑú Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: " << directory << std::endl;
        return false;
    }
    
    int successCount = 0;
    for (const auto& filePath : imageFiles) {
        // ÌååÏùºÎ™ÖÏóêÏÑú ÎùºÎ≤® Ï∂îÏ∂ú (ÌôïÏû•Ïûê Ï†úÍ±∞)
        std::string filename = std::filesystem::path(filePath).stem().string();
        
        if (addReferenceFace(filePath, filename)) {
            successCount++;
        }
    }
    
    std::cout << "üìö Îã§Ï§ë Í∏∞Ï§Ä ÏñºÍµ¥ Î°úÎìú ÏôÑÎ£å: " 
              << successCount << "/" << imageFiles.size() 
              << " Í∞ú ÏÑ±Í≥µ" << std::endl;
    
    return successCount > 0;
}

void MLFaceMatcher::clearReferenceData() {
    referenceFeatures.clear();
    labelCounts.clear();
    std::cout << "üóëÔ∏è Í∏∞Ï§Ä Îç∞Ïù¥ÌÑ∞ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å" << std::endl;
}

int MLFaceMatcher::getReferenceCount() const {
    return static_cast<int>(referenceFeatures.size());
}

// === ÎπÑÎîîÏò§ ÏÜåÏä§ Í¥ÄÎ¶¨ ===

bool MLFaceMatcher::startWebcam(int deviceId) {
    videoCapture.open(deviceId);
    if (!videoCapture.isOpened()) {
        std::cerr << "‚ùå ÏõπÏ∫† ÏãúÏûë Ïã§Ìå® (Device ID: " << deviceId << ")" << std::endl;
        return false;
    }
    
    // ÏõπÏ∫† ÏÑ§Ï†ï
    videoCapture.set(cv::CAP_PROP_FRAME_WIDTH, 640);
    videoCapture.set(cv::CAP_PROP_FRAME_HEIGHT, 480);
    videoCapture.set(cv::CAP_PROP_FPS, 30);
    
    videoSource = "webcam";
    isVideoFile = false;
    
    std::cout << "‚úÖ ÏõπÏ∫† ÏãúÏûë ÏôÑÎ£å!" << std::endl;
    return true;
}

bool MLFaceMatcher::loadVideoFile(const std::string& videoPath) {
    videoCapture.open(videoPath);
    if (!videoCapture.isOpened()) {
        std::cerr << "‚ùå ÎπÑÎîîÏò§ ÌååÏùº Î°úÎìú Ïã§Ìå®: " << videoPath << std::endl;
        return false;
    }
    
    videoSource = videoPath;
    isVideoFile = true;
    
    // ÎπÑÎîîÏò§ Ï†ïÎ≥¥ Ï∂úÎ†•
    int totalFrames = static_cast<int>(videoCapture.get(cv::CAP_PROP_FRAME_COUNT));
    double fps = videoCapture.get(cv::CAP_PROP_FPS);
    int width = static_cast<int>(videoCapture.get(cv::CAP_PROP_FRAME_WIDTH));
    int height = static_cast<int>(videoCapture.get(cv::CAP_PROP_FRAME_HEIGHT));
    
    std::cout << "‚úÖ ÎπÑÎîîÏò§ ÌååÏùº Î°úÎìú ÏôÑÎ£å!" << std::endl;
    std::cout << "üìÅ ÌååÏùº: " << videoPath << std::endl;
    std::cout << "üìä Ï†ïÎ≥¥: " << width << "x" << height 
              << ", " << fps << " FPS, " << totalFrames << " ÌîÑÎ†àÏûÑ" << std::endl;
    
    return true;
}

// === Ïã§ÏãúÍ∞Ñ Îß§Ïπ≠ Ïã§Ìñâ ===

void MLFaceMatcher::runFaceMatching() {
    if (!videoCapture.isOpened()) {
        std::cerr << "‚ùå ÎπÑÎîîÏò§ ÏÜåÏä§Í∞Ä Ïó¥Î†§ÏûàÏßÄ ÏïäÏäµÎãàÎã§!" << std::endl;
        return;
    }
    
    if (referenceFeatures.empty()) {
        std::cerr << "‚ùå Í∏∞Ï§Ä ÏñºÍµ¥ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§!" << std::endl;
        return;
    }
    
    std::string sourceType = isVideoFile ? "ÎπÑÎîîÏò§ ÌååÏùº" : "ÏõπÏ∫†";
    std::cout << "üé• ML Í∏∞Î∞ò " << sourceType << " ÏñºÍµ¥ Îß§Ïπ≠ ÏãúÏûë!" << std::endl;
    std::cout << "üìö ÌïôÏäµÎêú Í∏∞Ï§Ä ÏñºÍµ¥: " << referenceFeatures.size() << "Í∞ú" << std::endl;
    
    if (isVideoFile) {
        std::cout << "üìÅ ÌååÏùº: " << videoSource << std::endl;
    }
    
    std::cout << "\nüìã Ï°∞ÏûëÎ≤ï:" << std::endl;
    std::cout << "   - ESC ÎòêÎäî 'q': Ï¢ÖÎ£å" << std::endl;
    std::cout << "   - SPACE: ÏùºÏãúÏ†ïÏßÄ/Ïû¨ÏÉù (ÎπÑÎîîÏò§ ÌååÏùº)" << std::endl;
    std::cout << "   - 't': Îß§Ïπ≠ ÏûÑÍ≥ÑÍ∞í Ï°∞Ï†ï" << std::endl;
    std::cout << "   - 's': Ïä§ÌÅ¨Î¶∞ÏÉ∑ Ï†ÄÏû•" << std::endl;
    std::cout << "   - 'f': ÌäπÏßïÏ†ê ÌëúÏãú ÌÜ†Í∏Ä" << std::endl;
    std::cout << "   - 'p': ÏÑ±Îä• ÌÜµÍ≥Ñ Ï∂úÎ†•" << std::endl;
    std::cout << std::endl;
    
    cv::Mat frame;
    int frameCount = 0;
    int totalFrames = isVideoFile ? static_cast<int>(videoCapture.get(cv::CAP_PROP_FRAME_COUNT)) : 0;
    bool paused = false;
    bool showFeatures = false;
    
    MLFaceMatchingUtils::Timer frameTimer;
    
    while (true) {
        frameTimer.start();
        
        if (!paused || !isVideoFile) {
            videoCapture >> frame;
            if (frame.empty()) {
                if (isVideoFile) {
                    std::cout << "üìπ ÎπÑÎîîÏò§ Ïû¨ÏÉù ÏôÑÎ£å!" << std::endl;
                }
                break;
            }
            frameCount++;
        }
        
        // ÏñºÍµ¥ Îß§Ïπ≠ ÏàòÌñâ
        std::vector<MatchResult> matchResults = matchFacesInImage(frame);
        
        // Í≤∞Í≥º ÌëúÏãú
        for (const auto& result : matchResults) {
            drawMatchResult(frame, result);
            if (showFeatures && result.isMatch) {
                // Îß§Ïπ≠Îêú ÏñºÍµ¥Ïùò ÌäπÏßïÏ†ê ÌëúÏãúÎäî Î≥ÑÎèÑ Íµ¨ÌòÑ ÌïÑÏöî
            }
        }
        
        // Ï†ïÎ≥¥ ÌëúÏãú
        std::string title = "ML Face Matching - " + (isVideoFile ? "Video" : "Webcam");
        cv::putText(frame, title, cv::Point(10, 30), 
                   cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 255, 0), 2);
        
        cv::putText(frame, "References: " + std::to_string(referenceFeatures.size()), 
                   cv::Point(10, 60), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 255, 255), 1);
        cv::putText(frame, "Matches: " + std::to_string(matchResults.size()), 
                   cv::Point(10, 80), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 255, 255), 1);
        
        if (isVideoFile) {
            std::string frameInfo = "Frame: " + std::to_string(frameCount) + "/" + std::to_string(totalFrames);
            cv::putText(frame, frameInfo, cv::Point(10, 100), 
                       cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 255, 255), 1);
            
            if (paused) {
                cv::putText(frame, "PAUSED", cv::Point(frame.cols/2 - 50, 50), 
                           cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(0, 255, 255), 3);
            }
        }
        
        cv::imshow(title, frame);
        
        // ÏÑ±Îä• ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏
        double frameTime = frameTimer.getElapsedMs();
        updatePerformanceStats(frameTime, 0, 0); // ÏÑ∏Î∂Ä ÏãúÍ∞ÑÏùÄ matchFacesInImageÏóêÏÑú Ï∏°Ï†ï
        
        // ÌÇ§ ÏûÖÎ†• Ï≤òÎ¶¨
        int waitTime = isVideoFile ? 30 : 1;
        int key = cv::waitKey(waitTime) & 0xFF;
        
        if (key == 27 || key == 'q') { // ESC ÎòêÎäî 'q'
            break;
        } else if (key == ' ' && isVideoFile) { // SPACE - ÏùºÏãúÏ†ïÏßÄ/Ïû¨ÏÉù
            paused = !paused;
            std::cout << (paused ? "‚è∏Ô∏è ÏùºÏãúÏ†ïÏßÄ" : "‚ñ∂Ô∏è Ïû¨ÏÉù") << std::endl;
        } else if (key == 't') { // ÏûÑÍ≥ÑÍ∞í Ï°∞Ï†ï
            std::cout << "ÌòÑÏû¨ Îß§Ïπ≠ ÏûÑÍ≥ÑÍ∞í: " << matchThreshold << std::endl;
            std::cout << "ÏÉàÎ°úÏö¥ ÏûÑÍ≥ÑÍ∞í ÏûÖÎ†• (0.0-1.0): ";
            double newThreshold;
            std::cin >> newThreshold;
            setMatchThreshold(std::max(0.0, std::min(1.0, newThreshold)));
        } else if (key == 's') { // Ïä§ÌÅ¨Î¶∞ÏÉ∑
            std::string filename = "ml_screenshot_" + std::to_string(frameCount) + ".jpg";
            cv::imwrite(filename, frame);
            std::cout << "üì∏ Ïä§ÌÅ¨Î¶∞ÏÉ∑ Ï†ÄÏû•: " << filename << std::endl;
        } else if (key == 'f') { // ÌäπÏßïÏ†ê ÌëúÏãú ÌÜ†Í∏Ä
            showFeatures = !showFeatures;
            std::cout << "üéØ ÌäπÏßïÏ†ê ÌëúÏãú: " << (showFeatures ? "ON" : "OFF") << std::endl;
        } else if (key == 'p') { // ÏÑ±Îä• ÌÜµÍ≥Ñ Ï∂úÎ†•
            printPerformanceStats();
        }
    }
    
    cv::destroyAllWindows();
    printPerformanceStats();
    std::cout << "üëã ML ÏñºÍµ¥ Îß§Ïπ≠ Ï¢ÖÎ£å!" << std::endl;
}

// === Îã®Ïùº Ïù¥ÎØ∏ÏßÄ Îß§Ïπ≠ ===

std::vector<MatchResult> MLFaceMatcher::matchFacesInImage(const cv::Mat& image) {
    std::vector<MatchResult> results;
    
    MLFaceMatchingUtils::Timer extractionTimer;
    extractionTimer.start();
    
    // ÏñºÍµ¥ Í≤ÄÏ∂ú
    std::vector<cv::Rect> faces = detectFaces(image);
    stats.facesDetected += faces.size();
    
    double extractionTime = extractionTimer.getElapsedMs();
    
    MLFaceMatchingUtils::Timer matchingTimer;
    matchingTimer.start();
    
    // Í∞Å Í≤ÄÏ∂úÎêú ÏñºÍµ¥Ïóê ÎåÄÌï¥ ÌäπÏßï Îß§Ïπ≠ ÏàòÌñâ
    for (const auto& faceRect : faces) {
        cv::Rect expandedFace = expandFaceRect(faceRect, image.size());
        cv::Mat faceImage = image(expandedFace);
        
        // ÌäπÏßï Ï∂îÏ∂ú
        FaceFeatures queryFeatures = extractFaceFeatures(faceImage, expandedFace);
        
        if (!queryFeatures.descriptors.empty()) {
            // KNN Îß§Ïπ≠ ÏàòÌñâ
            MatchResult result = performKNNMatching(queryFeatures);
            result.faceRegion = expandedFace;
            
            if (validateMatch(result)) {
                results.push_back(result);
                if (result.isMatch) {
                    stats.facesMatched++;
                }
            }
        }
    }
    
    double matchingTime = matchingTimer.getElapsedMs();
    updatePerformanceStats(0, extractionTime, matchingTime);
    
    return results;
}

// === ÎÇ¥Î∂Ä Î©îÏÑúÎìú Íµ¨ÌòÑ ===

void MLFaceMatcher::initializeFeatureExtractor() {
    switch (currentExtractorType) {
        case FeatureExtractorType::SIFT:
            try {
                featureExtractor = cv::SIFT::create(500); // ÏµúÎåÄ 500Í∞ú ÌäπÏßïÏ†ê
                matcher = cv::BFMatcher::create(cv::NORM_L2, true);
            } catch (const cv::Exception& e) {
                std::cerr << "‚ö†Ô∏è SIFT ÏÉùÏÑ± Ïã§Ìå®, ORBÎ°ú ÎåÄÏ≤¥: " << e.what() << std::endl;
                currentExtractorType = FeatureExtractorType::ORB;
                initializeFeatureExtractor();
            }
            break;
            
        case FeatureExtractorType::ORB:
            featureExtractor = cv::ORB::create(500);
            matcher = cv::BFMatcher::create(cv::NORM_HAMMING, true);
            break;
            
        case FeatureExtractorType::AKAZE:
            featureExtractor = cv::AKAZE::create();
            matcher = cv::BFMatcher::create(cv::NORM_HAMMING, true);
            break;
    }
    
    if (!featureExtractor) {
        std::cerr << "‚ùå ÌäπÏßï Ï∂îÏ∂úÍ∏∞ ÏÉùÏÑ± Ïã§Ìå®!" << std::endl;
    }
}

bool MLFaceMatcher::initializeFaceDetector() {
    std::vector<std::string> cascadePaths = {
        "haarcascade_frontalface_default.xml",
        "haarcascade_frontalface_alt.xml",
        "/usr/share/opencv4/haarcascades/haarcascade_frontalface_default.xml",
        "/usr/local/share/opencv4/haarcascades/haarcascade_frontalface_default.xml"
    };
    
    for (const auto& path : cascadePaths) {
        if (faceClassifier.load(path)) {
            cascadeLoaded = true;
            std::cout << "‚úÖ ÏñºÍµ¥ Í≤ÄÏ∂úÍ∏∞ Î°úÎìú ÏÑ±Í≥µ: " << path << std::endl;
            return true;
        }
    }
    
    std::cerr << "‚ùå ÏñºÍµ¥ Í≤ÄÏ∂úÍ∏∞ Î°úÎìú Ïã§Ìå®!" << std::endl;
    return false;
}

std::vector<cv::Rect> MLFaceMatcher::detectFaces(const cv::Mat& frame) {
    std::vector<cv::Rect> faces;
    
    if (!cascadeLoaded || faceClassifier.empty() || frame.empty()) {
        return faces;
    }
    
    cv::Mat grayFrame;
    if (frame.channels() == 3) {
        cv::cvtColor(frame, grayFrame, cv::COLOR_BGR2GRAY);
    } else {
        grayFrame = frame.clone();
    }
    
    cv::equalizeHist(grayFrame, grayFrame);
    
    try {
        faceClassifier.detectMultiScale(
            grayFrame, faces,
            1.1, 3,
            0 | cv::CASCADE_SCALE_IMAGE,
            cv::Size(30, 30)
        );
    } catch (const cv::Exception& e) {
        std::cerr << "‚ùå ÏñºÍµ¥ Í≤ÄÏ∂ú Ïò§Î•ò: " << e.what() << std::endl;
    }
    
    return faces;
}

FaceFeatures MLFaceMatcher::extractFaceFeatures(const cv::Mat& faceImage, const cv::Rect& faceRegion) {
    FaceFeatures features;
    features.faceRegion = faceRegion;
    
    if (!featureExtractor || faceImage.empty()) {
        return features;
    }
    
    cv::Mat processedFace = faceImage.clone();
    if (!preprocessFace(processedFace)) {
        return features;
    }
    
    try {
        featureExtractor->detectAndCompute(processedFace, cv::noArray(), 
                                         features.keypoints, features.descriptors);
    } catch (const cv::Exception& e) {
        std::cerr << "‚ùå ÌäπÏßï Ï∂îÏ∂ú Ïò§Î•ò: " << e.what() << std::endl;
    }
    
    return features;
}

bool MLFaceMatcher::preprocessFace(cv::Mat& face) {
    if (face.empty()) return false;
    
    // ÌÅ¨Í∏∞ Ï†ïÍ∑úÌôî
    cv::resize(face, face, cv::Size(128, 128));
    
    // Ï°∞Î™Ö Ï†ïÍ∑úÌôî
    face = MLFaceMatchingUtils::normalizeIllumination(face);
    
    return true;
}

MatchResult MLFaceMatcher::performKNNMatching(const FaceFeatures& queryFeatures) {
    MatchResult result;
    
    if (queryFeatures.descriptors.empty() || referenceFeatures.empty()) {
        return result;
    }
    
    double bestDistance = std::numeric_limits<double>::max();
    std::string bestLabel;
    int bestMatchCount = 0;
    
    // Í∞Å Í∏∞Ï§Ä ÏñºÍµ¥Í≥º ÎπÑÍµê
    for (const auto& refFeature : referenceFeatures) {
        if (refFeature.descriptors.empty()) continue;
        
        try {
            std::vector<std::vector<cv::DMatch>> knnMatches;
            matcher->knnMatch(queryFeatures.descriptors, refFeature.descriptors, knnMatches, knnK);
            
            // Lowe's ratio test Ï†ÅÏö©
            std::vector<cv::DMatch> goodMatches = filterMatches(knnMatches);
            
            if (goodMatches.size() >= 4) { // ÏµúÏÜå Îß§Ïπ≠ Í∞úÏàò
                // Í±∞Î¶¨ Í≥ÑÏÇ∞
                double avgDistance = 0.0;
                for (const auto& match : goodMatches) {
                    avgDistance += match.distance;
                }
                avgDistance /= goodMatches.size();
                
                // Í∞ÄÏû• Ï¢ãÏùÄ Îß§Ïπ≠ ÏóÖÎç∞Ïù¥Ìä∏
                if (avgDistance < bestDistance && goodMatches.size() > bestMatchCount) {
                    bestDistance = avgDistance;
                    bestLabel = refFeature.label;
                    bestMatchCount = goodMatches.size();
                    result.matches = goodMatches;
                }
            }
        } catch (const cv::Exception& e) {
            std::cerr << "‚ùå Îß§Ïπ≠ Ïò§Î•ò: " << e.what() << std::endl;
        }
    }
    
    // Í≤∞Í≥º ÏÑ§Ï†ï
    if (bestMatchCount > 0) {
        result.distance = bestDistance;
        result.confidence = calculateConfidence(result.matches, bestDistance);
        result.matchedLabel = bestLabel;
        result.isMatch = (result.confidence > matchThreshold);
    }
    
    return result;
}

std::vector<cv::DMatch> MLFaceMatcher::filterMatches(const std::vector<std::vector<cv::DMatch>>& knnMatches) {
    std::vector<cv::DMatch> goodMatches;
    
    for (const auto& match : knnMatches) {
        if (match.size() == 2) {
            // Lowe's ratio test
            if (match[0].distance < ratioThreshold * match[1].distance) {
                goodMatches.push_back(match[0]);
            }
        } else if (match.size() == 1) {
            // Îã®Ïùº Îß§Ïπ≠Ïùò Í≤ΩÏö∞ Í±∞Î¶¨Í∞Ä Ï∂©Î∂ÑÌûà ÏûëÏùÄÏßÄ ÌôïÏù∏
            if (match[0].distance < 100.0) { // ÏûÑÍ≥ÑÍ∞íÏùÄ ÌäπÏßï Ï∂îÏ∂úÍ∏∞Ïóê Îî∞Îùº Ï°∞Ï†ï ÌïÑÏöî
                goodMatches.push_back(match[0]);
            }
        }
    }
    
    return goodMatches;
}

double MLFaceMatcher::calculateConfidence(const std::vector<cv::DMatch>& matches, double distance) {
    if (matches.empty()) return 0.0;
    
    // Îß§Ïπ≠ Í∞úÏàòÏôÄ ÌèâÍ∑† Í±∞Î¶¨Î•º Í≥†Î†§Ìïú Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞
    double matchRatio = static_cast<double>(matches.size()) / 100.0; // Ï†ïÍ∑úÌôî
    double distanceScore = std::max(0.0, 1.0 - distance / 200.0); // Í±∞Î¶¨ Ï†êÏàò
    
    return std::min(1.0, matchRatio * 0.6 + distanceScore * 0.4);
}

bool MLFaceMatcher::validateMatch(const MatchResult& result) {
    // Í∏∞Î≥∏ Í≤ÄÏ¶ù: ÏµúÏÜå Îß§Ïπ≠ Í∞úÏàòÏôÄ Í±∞Î¶¨ ÏûÑÍ≥ÑÍ∞í
    return result.matches.size() >= 3 && result.distance < 150.0;
}

void MLFaceMatcher::drawMatchResult(cv::Mat& frame, const MatchResult& result) {
    cv::Scalar color = result.isMatch ? cv::Scalar(0, 0, 255) : cv::Scalar(0, 255, 255); // Îπ®Í∞ï ÎòêÎäî ÎÖ∏Îûë
    int thickness = result.isMatch ? 4 : 2;
    
    // ÏÇ¨Í∞ÅÌòï Í∑∏Î¶¨Í∏∞
    cv::rectangle(frame, result.faceRegion, color, thickness);
    
    // Î†àÏù¥Î∏îÍ≥º Ïã†Î¢∞ÎèÑ ÌëúÏãú
    std::string text;
    if (result.isMatch) {
        text = result.matchedLabel + " (" + std::to_string(static_cast<int>(result.confidence * 100)) + "%)";
    } else {
        text = "Unknown (" + std::to_string(static_cast<int>(result.confidence * 100)) + "%)";
    }
    
    cv::Point textPos(result.faceRegion.x, result.faceRegion.y - 10);
    cv::putText(frame, text, textPos, cv::FONT_HERSHEY_SIMPLEX, 0.6, color, 2);
    
    // Îß§Ïπ≠Îêú Í≤ΩÏö∞ Ï∂îÍ∞Ä ÌëúÏãú
    if (result.isMatch) {
        cv::Point center(result.faceRegion.x + result.faceRegion.width/2, 
                        result.faceRegion.y + result.faceRegion.height/2);
        int radius = std::max(result.faceRegion.width, result.faceRegion.height) / 2 + 10;
        cv::circle(frame, center, radius, cv::Scalar(0, 0, 255), 3);
        
        // Îß§Ïπ≠ Ï†ïÎ≥¥
        std::string matchInfo = "Matches: " + std::to_string(result.matches.size());
        cv::putText(frame, matchInfo, 
                   cv::Point(result.faceRegion.x, result.faceRegion.y + result.faceRegion.height + 20),
                   cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 255), 1);
    }
}

cv::Rect MLFaceMatcher::expandFaceRect(const cv::Rect& face, const cv::Size& imageSize, double factor) {
    int newWidth = static_cast<int>(face.width * factor);
    int newHeight = static_cast<int>(face.height * factor);
    
    int newX = face.x - (newWidth - face.width) / 2;
    int newY = face.y - (newHeight - face.height) / 2;
    
    // Ïù¥ÎØ∏ÏßÄ Í≤ΩÍ≥Ñ ÎÇ¥Î°ú Ï†úÌïú
    newX = std::max(0, newX);
    newY = std::max(0, newY);
    newWidth = std::min(imageSize.width - newX, newWidth);
    newHeight = std::min(imageSize.height - newY, newHeight);
    
    return cv::Rect(newX, newY, newWidth, newHeight);
}

void MLFaceMatcher::updatePerformanceStats(double frameTime, double extractionTime, double matchingTime) {
    stats.totalFrames++;
    stats.totalProcessingTime += frameTime;
    if (extractionTime > 0) stats.avgFeatureExtractionTime += extractionTime;
    if (matchingTime > 0) stats.avgMatchingTime += matchingTime;
}

void MLFaceMatcher::printPerformanceStats() {
    std::cout << "\nüìä ÏÑ±Îä• ÌÜµÍ≥Ñ:" << std::endl;
    std::cout << "   - Ï¥ù ÌîÑÎ†àÏûÑ: " << stats.totalFrames << std::endl;
    std::cout << "   - Í≤ÄÏ∂úÎêú ÏñºÍµ¥: " << stats.facesDetected << std::endl;
    std::cout << "   - Îß§Ïπ≠Îêú ÏñºÍµ¥: " << stats.facesMatched << std::endl;
    std::cout << "   - Îß§Ïπ≠Î•†: " << (stats.facesDetected > 0 ? 
                   (double)stats.facesMatched / stats.facesDetected * 100 : 0) << "%" << std::endl;
    std::cout << "   - ÌèâÍ∑† ÌîÑÎ†àÏûÑ Ï≤òÎ¶¨ ÏãúÍ∞Ñ: " << 
                 (stats.totalFrames > 0 ? stats.totalProcessingTime / stats.totalFrames : 0) << "ms" << std::endl;
    std::cout << std::endl;
}

// === Ïú†Ìã∏Î¶¨Ìã∞ Ìï®Ïàò Íµ¨ÌòÑ ===

namespace MLFaceMatchingUtils {
    
    Timer::Timer() {}
    
    void Timer::start() {
        startTime = std::chrono::high_resolution_clock::now();
    }
    
    double Timer::getElapsedMs() {
        auto endTime = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::microseconds>(endTime - startTime);
        return duration.count() / 1000.0; // Î∞ÄÎ¶¨Ï¥àÎ°ú Î≥ÄÌôò
    }
    
    cv::Mat normalizeIllumination(const cv::Mat& image) {
        cv::Mat result;
        if (image.channels() == 3) {
            cv::Mat lab;
            cv::cvtColor(image, lab, cv::COLOR_BGR2Lab);
            
            std::vector<cv::Mat> labChannels;
            cv::split(lab, labChannels);
            
            cv::Ptr<cv::CLAHE> clahe = cv::createCLAHE(2.0, cv::Size(8, 8));
            clahe->apply(labChannels[0], labChannels[0]);
            
            cv::merge(labChannels, lab);
            cv::cvtColor(lab, result, cv::COLOR_Lab2BGR);
        } else {
            cv::Ptr<cv::CLAHE> clahe = cv::createCLAHE(2.0, cv::Size(8, 8));
            clahe->apply(image, result);
        }
        return result;
    }
    
    std::vector<std::string> getImageFiles(const std::string& directory) {
        std::vector<std::string> imageFiles;
        std::vector<std::string> extensions = {".jpg", ".jpeg", ".png", ".bmp", ".tiff"};
        
        try {
            for (const auto& entry : std::filesystem::directory_iterator(directory)) {
                if (entry.is_regular_file()) {
                    std::string filePath = entry.path().string();
                    std::string extension = entry.path().extension().string();
                    std::transform(extension.begin(), extension.end(), extension.begin(), ::tolower);
                    
                    if (std::find(extensions.begin(), extensions.end(), extension) != extensions.end()) {
                        imageFiles.push_back(filePath);
                    }
                }
            }
        } catch (const std::filesystem::filesystem_error& e) {
            std::cerr << "‚ùå ÎîîÎ†âÌÑ∞Î¶¨ ÏùΩÍ∏∞ Ïò§Î•ò: " << e.what() << std::endl;
        }
        
        return imageFiles;
    }
}